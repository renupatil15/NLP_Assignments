{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from textblob import TextBlob\n",
        "import spacy\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"\"\"I spent my vacation at home. During this time, I practiced coding and engaged in\n",
        "creative activities such as painting and trekking. I followed my hobbies, relaxed,\n",
        "and enjoyed my free time. On some days, I visited my aunt’s house, where there is a dog.\n",
        "I spent my whole day with that dog, as I love animals very much. Being there made me\n",
        "extremely happy. This is how I spent my vacation.\"\"\"\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "print(\"\\nTOKENS:\")\n",
        "print(tokens)\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stems = [stemmer.stem(word) for word in tokens]\n",
        "print(\"\\nSTEMMING:\")\n",
        "print(stems)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmas = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "print(\"\\nLEMMATIZATION:\")\n",
        "print(lemmas)\n",
        "\n",
        "pos_tags = nltk.pos_tag(tokens, lang='eng')\n",
        "print(\"\\nPOS TAGGING (NLTK):\")\n",
        "print(pos_tags)\n",
        "\n",
        "print(\"\\nPOS TAGGING (SPACY):\")\n",
        "doc = nlp(text)\n",
        "for token in doc:\n",
        "    print(f\"{token.text} -> {token.pos_}\")\n",
        "\n",
        "blob = TextBlob(text)\n",
        "print(\"\\nSENTIMENT ANALYSIS:\")\n",
        "print(\"Polarity:\", blob.sentiment.polarity)\n",
        "print(\"Subjectivity:\", blob.sentiment.subjectivity)\n",
        "\n",
        "if blob.sentiment.polarity > 0:\n",
        "    print(\"Overall Sentiment: Positive \")\n",
        "elif blob.sentiment.polarity < 0:\n",
        "    print(\"Overall Sentiment: Negative \")\n",
        "else:\n",
        "    print(\"Overall Sentiment: Neutral \")\n"
      ],
      "metadata": {
        "id": "ma_dw0sZvzQ9",
        "outputId": "d3eaf03d-1150-4f1b-be0b-13d550c6c100",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ma_dw0sZvzQ9",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TOKENS:\n",
            "['I', 'spent', 'my', 'vacation', 'at', 'home', '.', 'During', 'this', 'time', ',', 'I', 'practiced', 'coding', 'and', 'engaged', 'in', 'creative', 'activities', 'such', 'as', 'painting', 'and', 'trekking', '.', 'I', 'followed', 'my', 'hobbies', ',', 'relaxed', ',', 'and', 'enjoyed', 'my', 'free', 'time', '.', 'On', 'some', 'days', ',', 'I', 'visited', 'my', 'aunt', '’', 's', 'house', ',', 'where', 'there', 'is', 'a', 'dog', '.', 'I', 'spent', 'my', 'whole', 'day', 'with', 'that', 'dog', ',', 'as', 'I', 'love', 'animals', 'very', 'much', '.', 'Being', 'there', 'made', 'me', 'extremely', 'happy', '.', 'This', 'is', 'how', 'I', 'spent', 'my', 'vacation', '.']\n",
            "\n",
            "STEMMING:\n",
            "['i', 'spent', 'my', 'vacat', 'at', 'home', '.', 'dure', 'thi', 'time', ',', 'i', 'practic', 'code', 'and', 'engag', 'in', 'creativ', 'activ', 'such', 'as', 'paint', 'and', 'trek', '.', 'i', 'follow', 'my', 'hobbi', ',', 'relax', ',', 'and', 'enjoy', 'my', 'free', 'time', '.', 'on', 'some', 'day', ',', 'i', 'visit', 'my', 'aunt', '’', 's', 'hous', ',', 'where', 'there', 'is', 'a', 'dog', '.', 'i', 'spent', 'my', 'whole', 'day', 'with', 'that', 'dog', ',', 'as', 'i', 'love', 'anim', 'veri', 'much', '.', 'be', 'there', 'made', 'me', 'extrem', 'happi', '.', 'thi', 'is', 'how', 'i', 'spent', 'my', 'vacat', '.']\n",
            "\n",
            "LEMMATIZATION:\n",
            "['I', 'spent', 'my', 'vacation', 'at', 'home', '.', 'During', 'this', 'time', ',', 'I', 'practiced', 'coding', 'and', 'engaged', 'in', 'creative', 'activity', 'such', 'a', 'painting', 'and', 'trekking', '.', 'I', 'followed', 'my', 'hobby', ',', 'relaxed', ',', 'and', 'enjoyed', 'my', 'free', 'time', '.', 'On', 'some', 'day', ',', 'I', 'visited', 'my', 'aunt', '’', 's', 'house', ',', 'where', 'there', 'is', 'a', 'dog', '.', 'I', 'spent', 'my', 'whole', 'day', 'with', 'that', 'dog', ',', 'a', 'I', 'love', 'animal', 'very', 'much', '.', 'Being', 'there', 'made', 'me', 'extremely', 'happy', '.', 'This', 'is', 'how', 'I', 'spent', 'my', 'vacation', '.']\n",
            "\n",
            "POS TAGGING (NLTK):\n",
            "[('I', 'PRP'), ('spent', 'VBD'), ('my', 'PRP$'), ('vacation', 'NN'), ('at', 'IN'), ('home', 'NN'), ('.', '.'), ('During', 'IN'), ('this', 'DT'), ('time', 'NN'), (',', ','), ('I', 'PRP'), ('practiced', 'VBD'), ('coding', 'VBG'), ('and', 'CC'), ('engaged', 'VBN'), ('in', 'IN'), ('creative', 'JJ'), ('activities', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('painting', 'NN'), ('and', 'CC'), ('trekking', 'NN'), ('.', '.'), ('I', 'PRP'), ('followed', 'VBD'), ('my', 'PRP$'), ('hobbies', 'NNS'), (',', ','), ('relaxed', 'VBN'), (',', ','), ('and', 'CC'), ('enjoyed', 'VB'), ('my', 'PRP$'), ('free', 'JJ'), ('time', 'NN'), ('.', '.'), ('On', 'IN'), ('some', 'DT'), ('days', 'NNS'), (',', ','), ('I', 'PRP'), ('visited', 'VBD'), ('my', 'PRP$'), ('aunt', 'NN'), ('’', 'NNP'), ('s', 'NN'), ('house', 'NN'), (',', ','), ('where', 'WRB'), ('there', 'EX'), ('is', 'VBZ'), ('a', 'DT'), ('dog', 'NN'), ('.', '.'), ('I', 'PRP'), ('spent', 'VBD'), ('my', 'PRP$'), ('whole', 'JJ'), ('day', 'NN'), ('with', 'IN'), ('that', 'DT'), ('dog', 'NN'), (',', ','), ('as', 'IN'), ('I', 'PRP'), ('love', 'VBP'), ('animals', 'NNS'), ('very', 'RB'), ('much', 'RB'), ('.', '.'), ('Being', 'VBG'), ('there', 'RB'), ('made', 'VBN'), ('me', 'PRP'), ('extremely', 'RB'), ('happy', 'JJ'), ('.', '.'), ('This', 'DT'), ('is', 'VBZ'), ('how', 'WRB'), ('I', 'PRP'), ('spent', 'VBD'), ('my', 'PRP$'), ('vacation', 'NN'), ('.', '.')]\n",
            "\n",
            "POS TAGGING (SPACY):\n",
            "I -> PRON\n",
            "spent -> VERB\n",
            "my -> PRON\n",
            "vacation -> NOUN\n",
            "at -> ADP\n",
            "home -> NOUN\n",
            ". -> PUNCT\n",
            "During -> ADP\n",
            "this -> DET\n",
            "time -> NOUN\n",
            ", -> PUNCT\n",
            "I -> PRON\n",
            "practiced -> VERB\n",
            "coding -> VERB\n",
            "and -> CCONJ\n",
            "engaged -> VERB\n",
            "in -> ADP\n",
            "\n",
            " -> SPACE\n",
            "creative -> ADJ\n",
            "activities -> NOUN\n",
            "such -> ADJ\n",
            "as -> ADP\n",
            "painting -> NOUN\n",
            "and -> CCONJ\n",
            "trekking -> NOUN\n",
            ". -> PUNCT\n",
            "I -> PRON\n",
            "followed -> VERB\n",
            "my -> PRON\n",
            "hobbies -> NOUN\n",
            ", -> PUNCT\n",
            "relaxed -> VERB\n",
            ", -> PUNCT\n",
            "\n",
            " -> SPACE\n",
            "and -> CCONJ\n",
            "enjoyed -> VERB\n",
            "my -> PRON\n",
            "free -> ADJ\n",
            "time -> NOUN\n",
            ". -> PUNCT\n",
            "On -> ADP\n",
            "some -> DET\n",
            "days -> NOUN\n",
            ", -> PUNCT\n",
            "I -> PRON\n",
            "visited -> VERB\n",
            "my -> PRON\n",
            "aunt -> NOUN\n",
            "’s -> PART\n",
            "house -> NOUN\n",
            ", -> PUNCT\n",
            "where -> SCONJ\n",
            "there -> PRON\n",
            "is -> VERB\n",
            "a -> DET\n",
            "dog -> NOUN\n",
            ". -> PUNCT\n",
            "\n",
            " -> SPACE\n",
            "I -> PRON\n",
            "spent -> VERB\n",
            "my -> PRON\n",
            "whole -> ADJ\n",
            "day -> NOUN\n",
            "with -> ADP\n",
            "that -> DET\n",
            "dog -> NOUN\n",
            ", -> PUNCT\n",
            "as -> SCONJ\n",
            "I -> PRON\n",
            "love -> VERB\n",
            "animals -> NOUN\n",
            "very -> ADV\n",
            "much -> ADV\n",
            ". -> PUNCT\n",
            "Being -> AUX\n",
            "there -> ADV\n",
            "made -> VERB\n",
            "me -> PRON\n",
            "\n",
            " -> SPACE\n",
            "extremely -> ADV\n",
            "happy -> ADJ\n",
            ". -> PUNCT\n",
            "This -> PRON\n",
            "is -> AUX\n",
            "how -> SCONJ\n",
            "I -> PRON\n",
            "spent -> VERB\n",
            "my -> PRON\n",
            "vacation -> NOUN\n",
            ". -> PUNCT\n",
            "\n",
            "SENTIMENT ANALYSIS:\n",
            "Polarity: 0.26\n",
            "Subjectivity: 0.5054545454545454\n",
            "Overall Sentiment: Positive \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0rwkXW5cvzUS"
      },
      "id": "0rwkXW5cvzUS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import WhitespaceTokenizer, WordPunctTokenizer\n",
        "from nltk.tokenize import TreebankWordTokenizer, TweetTokenizer\n",
        "from nltk.tokenize import MWETokenizer\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "text = \"\"\"I spent my vacation at home. During this time, I practiced coding and engaged in\n",
        "creative activities such as painting and trekking. I followed my hobbies, relaxed,\n",
        "and enjoyed my free time. On some days, I visited my aunt’s house, where there is a dog.\n",
        "I spent my whole day with that dog, as I love animals very much. Being there made me\n",
        "extremely happy. This is how I spent my vacation.\"\"\"\n",
        "\n",
        "# Whitespace Tokenization\n",
        "wt = WhitespaceTokenizer()\n",
        "print(\"\\nWhitespace Tokenization:\")\n",
        "print(wt.tokenize(text))\n",
        "\n",
        "# Punctuation-based Tokenization\n",
        "pt = WordPunctTokenizer()\n",
        "print(\"\\nPunctuation-based Tokenization:\")\n",
        "print(pt.tokenize(text))\n",
        "\n",
        "# Treebank Tokenization\n",
        "tbt = TreebankWordTokenizer()\n",
        "print(\"\\nTreebank Tokenization:\")\n",
        "print(tbt.tokenize(text))\n",
        "\n",
        "# Tweet Tokenization\n",
        "tweet = TweetTokenizer()\n",
        "print(\"\\nTweet Tokenization:\")\n",
        "print(tweet.tokenize(text))\n",
        "\n",
        "# MWE Tokenization\n",
        "mwe = MWETokenizer([('creative', 'activities'), ('vacation', 'at', 'home')], separator='_')\n",
        "print(\"\\nMWE Tokenization:\")\n",
        "print(mwe.tokenize(text.split()))\n",
        "\n",
        "# Stemming\n",
        "porter = PorterStemmer()\n",
        "snowball = SnowballStemmer(\"english\")\n",
        "\n",
        "tokens = tbt.tokenize(text)\n",
        "\n",
        "print(\"\\nPorter Stemming:\")\n",
        "print([porter.stem(word) for word in tokens])\n",
        "\n",
        "print(\"\\nSnowball Stemming:\")\n",
        "print([snowball.stem(word) for word in tokens])\n",
        "\n",
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print(\"\\nLemmatization:\")\n",
        "print([lemmatizer.lemmatize(word) for word in tokens])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLIT7jN_mswy",
        "outputId": "bfdef82d-c4d4-4c53-f235-08714ca35068"
      },
      "id": "tLIT7jN_mswy",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Whitespace Tokenization:\n",
            "['I', 'spent', 'my', 'vacation', 'at', 'home.', 'During', 'this', 'time,', 'I', 'practiced', 'coding', 'and', 'engaged', 'in', 'creative', 'activities', 'such', 'as', 'painting', 'and', 'trekking.', 'I', 'followed', 'my', 'hobbies,', 'relaxed,', 'and', 'enjoyed', 'my', 'free', 'time.', 'On', 'some', 'days,', 'I', 'visited', 'my', 'aunt’s', 'house,', 'where', 'there', 'is', 'a', 'dog.', 'I', 'spent', 'my', 'whole', 'day', 'with', 'that', 'dog,', 'as', 'I', 'love', 'animals', 'very', 'much.', 'Being', 'there', 'made', 'me', 'extremely', 'happy.', 'This', 'is', 'how', 'I', 'spent', 'my', 'vacation.']\n",
            "\n",
            "Punctuation-based Tokenization:\n",
            "['I', 'spent', 'my', 'vacation', 'at', 'home', '.', 'During', 'this', 'time', ',', 'I', 'practiced', 'coding', 'and', 'engaged', 'in', 'creative', 'activities', 'such', 'as', 'painting', 'and', 'trekking', '.', 'I', 'followed', 'my', 'hobbies', ',', 'relaxed', ',', 'and', 'enjoyed', 'my', 'free', 'time', '.', 'On', 'some', 'days', ',', 'I', 'visited', 'my', 'aunt', '’', 's', 'house', ',', 'where', 'there', 'is', 'a', 'dog', '.', 'I', 'spent', 'my', 'whole', 'day', 'with', 'that', 'dog', ',', 'as', 'I', 'love', 'animals', 'very', 'much', '.', 'Being', 'there', 'made', 'me', 'extremely', 'happy', '.', 'This', 'is', 'how', 'I', 'spent', 'my', 'vacation', '.']\n",
            "\n",
            "Treebank Tokenization:\n",
            "['I', 'spent', 'my', 'vacation', 'at', 'home.', 'During', 'this', 'time', ',', 'I', 'practiced', 'coding', 'and', 'engaged', 'in', 'creative', 'activities', 'such', 'as', 'painting', 'and', 'trekking.', 'I', 'followed', 'my', 'hobbies', ',', 'relaxed', ',', 'and', 'enjoyed', 'my', 'free', 'time.', 'On', 'some', 'days', ',', 'I', 'visited', 'my', 'aunt’s', 'house', ',', 'where', 'there', 'is', 'a', 'dog.', 'I', 'spent', 'my', 'whole', 'day', 'with', 'that', 'dog', ',', 'as', 'I', 'love', 'animals', 'very', 'much.', 'Being', 'there', 'made', 'me', 'extremely', 'happy.', 'This', 'is', 'how', 'I', 'spent', 'my', 'vacation', '.']\n",
            "\n",
            "Tweet Tokenization:\n",
            "['I', 'spent', 'my', 'vacation', 'at', 'home', '.', 'During', 'this', 'time', ',', 'I', 'practiced', 'coding', 'and', 'engaged', 'in', 'creative', 'activities', 'such', 'as', 'painting', 'and', 'trekking', '.', 'I', 'followed', 'my', 'hobbies', ',', 'relaxed', ',', 'and', 'enjoyed', 'my', 'free', 'time', '.', 'On', 'some', 'days', ',', 'I', 'visited', 'my', 'aunt', '’', 's', 'house', ',', 'where', 'there', 'is', 'a', 'dog', '.', 'I', 'spent', 'my', 'whole', 'day', 'with', 'that', 'dog', ',', 'as', 'I', 'love', 'animals', 'very', 'much', '.', 'Being', 'there', 'made', 'me', 'extremely', 'happy', '.', 'This', 'is', 'how', 'I', 'spent', 'my', 'vacation', '.']\n",
            "\n",
            "MWE Tokenization:\n",
            "['I', 'spent', 'my', 'vacation', 'at', 'home.', 'During', 'this', 'time,', 'I', 'practiced', 'coding', 'and', 'engaged', 'in', 'creative_activities', 'such', 'as', 'painting', 'and', 'trekking.', 'I', 'followed', 'my', 'hobbies,', 'relaxed,', 'and', 'enjoyed', 'my', 'free', 'time.', 'On', 'some', 'days,', 'I', 'visited', 'my', 'aunt’s', 'house,', 'where', 'there', 'is', 'a', 'dog.', 'I', 'spent', 'my', 'whole', 'day', 'with', 'that', 'dog,', 'as', 'I', 'love', 'animals', 'very', 'much.', 'Being', 'there', 'made', 'me', 'extremely', 'happy.', 'This', 'is', 'how', 'I', 'spent', 'my', 'vacation.']\n",
            "\n",
            "Porter Stemming:\n",
            "['i', 'spent', 'my', 'vacat', 'at', 'home.', 'dure', 'thi', 'time', ',', 'i', 'practic', 'code', 'and', 'engag', 'in', 'creativ', 'activ', 'such', 'as', 'paint', 'and', 'trekking.', 'i', 'follow', 'my', 'hobbi', ',', 'relax', ',', 'and', 'enjoy', 'my', 'free', 'time.', 'on', 'some', 'day', ',', 'i', 'visit', 'my', 'aunt’', 'hous', ',', 'where', 'there', 'is', 'a', 'dog.', 'i', 'spent', 'my', 'whole', 'day', 'with', 'that', 'dog', ',', 'as', 'i', 'love', 'anim', 'veri', 'much.', 'be', 'there', 'made', 'me', 'extrem', 'happy.', 'thi', 'is', 'how', 'i', 'spent', 'my', 'vacat', '.']\n",
            "\n",
            "Snowball Stemming:\n",
            "['i', 'spent', 'my', 'vacat', 'at', 'home.', 'dure', 'this', 'time', ',', 'i', 'practic', 'code', 'and', 'engag', 'in', 'creativ', 'activ', 'such', 'as', 'paint', 'and', 'trekking.', 'i', 'follow', 'my', 'hobbi', ',', 'relax', ',', 'and', 'enjoy', 'my', 'free', 'time.', 'on', 'some', 'day', ',', 'i', 'visit', 'my', 'aunt', 'hous', ',', 'where', 'there', 'is', 'a', 'dog.', 'i', 'spent', 'my', 'whole', 'day', 'with', 'that', 'dog', ',', 'as', 'i', 'love', 'anim', 'veri', 'much.', 'be', 'there', 'made', 'me', 'extrem', 'happy.', 'this', 'is', 'how', 'i', 'spent', 'my', 'vacat', '.']\n",
            "\n",
            "Lemmatization:\n",
            "['I', 'spent', 'my', 'vacation', 'at', 'home.', 'During', 'this', 'time', ',', 'I', 'practiced', 'coding', 'and', 'engaged', 'in', 'creative', 'activity', 'such', 'a', 'painting', 'and', 'trekking.', 'I', 'followed', 'my', 'hobby', ',', 'relaxed', ',', 'and', 'enjoyed', 'my', 'free', 'time.', 'On', 'some', 'day', ',', 'I', 'visited', 'my', 'aunt’s', 'house', ',', 'where', 'there', 'is', 'a', 'dog.', 'I', 'spent', 'my', 'whole', 'day', 'with', 'that', 'dog', ',', 'a', 'I', 'love', 'animal', 'very', 'much.', 'Being', 'there', 'made', 'me', 'extremely', 'happy.', 'This', 'is', 'how', 'I', 'spent', 'my', 'vacation', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}